{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "htSU2KhD5_NL",
    "outputId": "e3c88a80-b003-438a-f43d-19a39978004f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-11b4cd50a334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import gc\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyZLd7pg5_NU"
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"data/chest_xray/chest_xray\")\n",
    "train_dir= data_dir/'train'\n",
    "val_dir=data_dir/'val'\n",
    "test_dir = data_dir / 'test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JALzR-VI5_NY"
   },
   "source": [
    "A basic function to load train images from the directory and save it in a dataframe with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNukbkcM5_NZ"
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    normal_cases_dir = train_dir / 'NORMAL'\n",
    "    pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "    # Get the list of all the images\n",
    "    normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "    pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "    train_data=[]\n",
    "    train_label=[]\n",
    "    for img in normal_cases:\n",
    "            train_data.append(img)\n",
    "            train_label.append(0)\n",
    "    for img in pneumonia_cases:\n",
    "        train_data.append(img)\n",
    "        train_label.append(1)\n",
    "    df=pd.DataFrame(train_data)\n",
    "    df.columns=['images']\n",
    "    df['labels']=train_label\n",
    "    df=df.sample(frac=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RjlLS1w5_Ne",
    "outputId": "e4e76c56-940e-4353-d1e3-8cf85a71f0b7"
   },
   "outputs": [],
   "source": [
    "train_data=load_train()\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EuFYnbgZ5_Nm"
   },
   "source": [
    "### Loading and preprocessing validation and test data\n",
    "Steps:-\n",
    "* Load the image using imread()\n",
    "* Since the images are of different length and widths, resize them to 224,224.\n",
    "* Some images in our data are greyscale (1 channel) , therefore convert them to 3 channel\n",
    "* Images using cv2 are read in BGR format(by default) , convert it to RGB.\n",
    "* Normalize the image pixels by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzP9Mbnn5_Nn"
   },
   "outputs": [],
   "source": [
    "def prepare_and_load(isval=True):\n",
    "    if isval==True:\n",
    "        normal_dir=val_dir/'NORMAL'\n",
    "        pneumonia_dir=val_dir/'PNEUMONIA'\n",
    "    else:\n",
    "        normal_dir=test_dir/'NORMAL'\n",
    "        pneumonia_dir=test_dir/'PNEUMONIA'\n",
    "    normal_cases = normal_dir.glob('*.jpeg')\n",
    "    pneumonia_cases = pneumonia_dir.glob('*.jpeg')\n",
    "    data,labels=([] for x in range(2))\n",
    "    def prepare(case):\n",
    "        for img in case:\n",
    "            img = cv2.imread(str(img))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            if img.shape[2] ==1:\n",
    "                 img = np.dstack([img, img, img])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32)/255.\n",
    "            if case==normal_cases:\n",
    "                label = to_categorical(0, num_classes=2)\n",
    "            else:\n",
    "                label = to_categorical(1, num_classes=2)\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "        return data,labels\n",
    "    prepare(normal_cases)\n",
    "    d,l=prepare(pneumonia_cases)\n",
    "    d=np.array(d)\n",
    "    l=np.array(l)\n",
    "    return d,l\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trDsG_7w5_Np"
   },
   "outputs": [],
   "source": [
    "val_data,val_labels=prepare_and_load(isval=True)\n",
    "test_data,test_labels=prepare_and_load(isval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAG69Itl5_Ns"
   },
   "source": [
    "### Generating batches of images for training\n",
    "* It involves the same preprocessing steps as above, except that images are processed and returned in batches,defined by the batch size.\n",
    "* We also use Image segmentation ( the slic function of skimage).Image segmentation is the process of partitioning a  image into multiple segments (sets of pixels, also known as super-pixels). The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze.\n",
    "* The dataset we have is Imbalanced and has pneumonia cases three times the normal cases.The goal of our model is to optimize accuracy while training , which it can easily do by classifying most of the cases as infected(since the majority cases are infected, the model will have high accuracy), but it is biased aginst the underrepresented class.Thus we try to augment images of the normal class , by adding flipped , rotated and changing brightness of the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPKzfpB85_Nt"
   },
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['images']\n",
    "            label = data.iloc[idx]['labels']\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "            \n",
    "            # check if it's grayscale\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "            \n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "            \n",
    "            #segmentation\n",
    "            oig_img=slic(orig_img) \n",
    "            \n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "            #augmentation\n",
    "            seq = iaa.OneOf([\n",
    "                 iaa.Fliplr(), # horizontal flips\n",
    "                 iaa.Affine(rotate=20), # roatation\n",
    "                 iaa.Multiply((1.2, 1.5))]) #random brightness\n",
    "            # generating more samples of the undersampled class\n",
    "            if label==0 and count < batch_size-2:\n",
    "                aug_img1 = seq.augment_image(img)\n",
    "                aug_img2 = seq.augment_image(img)\n",
    "                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "                batch_data[count+1] = aug_img1\n",
    "                batch_labels[count+1] = encoded_label\n",
    "                batch_data[count+2] = aug_img2\n",
    "                batch_labels[count+2] = encoded_label\n",
    "                count +=2\n",
    "            \n",
    "            else:\n",
    "                count+=1\n",
    "            \n",
    "            if count==batch_size-1:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_data, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CQIuPtK5_N0"
   },
   "outputs": [],
   "source": [
    "def vgg16_model( num_classes=None):\n",
    "\n",
    "    model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "    x=Dense(1024, activation='relu')(model.layers[-4].output)# add my own dense layer after the last conv block\n",
    "    x=Dropout(0.7)(x)\n",
    "    x=Dense(512,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    x=Dense(2,activation='softmax')(x)\n",
    "    model=Model(model.input,x)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTLDb2ti5_N4",
    "outputId": "a5287270-94c7-4646-c0e0-340a99dc8781"
   },
   "outputs": [],
   "source": [
    "vgg_conv=vgg16_model(2)\n",
    "for layer in vgg_conv.layers[:-10]:#freeze all layers except the last ten\n",
    "    layer.trainable = False\n",
    " \n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3B0DOP85_N8",
    "outputId": "0e6e632a-50f4-440c-bfc5-35cebd25536d"
   },
   "outputs": [],
   "source": [
    "vgg_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnW_IqYz5_OB"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "early_stop = EarlyStopping(monitor='loss',patience=3,verbose=1)\n",
    "vgg_conv.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxzsbHCW5_OE",
    "outputId": "fb9737ec-c26a-4396-bd9e-2541d107adbb"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_epochs = 5\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxCFDc5Y5_OI",
    "outputId": "b1457f89-7ac1-4576-a318-986c69cd6597"
   },
   "outputs": [],
   "source": [
    "# # Fit the model\n",
    "history = vgg_conv.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "                              validation_data=(val_data,val_labels),callbacks=[early_stop],\n",
    "                               class_weight={0:1.0, 1:0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "740AB4j95_OP"
   },
   "source": [
    "Let's see how it does on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HGuoCw5_OT",
    "outputId": "f7d4624e-8547-4990-b4d3-56c1512e4de2"
   },
   "outputs": [],
   "source": [
    "loss,acc=vgg_conv.evaluate(test_data,test_labels,batch_size=16)\n",
    "print('Loss and accuracy',loss,'&',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9V5gCYl5_Oa"
   },
   "source": [
    "Since we are working on Imbalanced data, accuracy is not really a trustworthy measure.Let's view the classification report first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEW-EOV35_Oc",
    "outputId": "62bfdc80-f821-47d6-f725-fa7e9af6b799"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "pred = vgg_conv.predict(test_data, batch_size=16)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "labels = np.argmax(test_labels, axis=-1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kzo7MwwM5_Ox"
   },
   "source": [
    "**Precision** is a fraction of people actually having pneumonia to all those predicted by the model as having pneumonia. **Recall/Sensitivity** on the other hand refers to the fraction of people actually having pneumonia and are predicted positive by the model to the total number of people having pneumonia. Hence, it relates to the potential of a test to recognise subjects with the disease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVLNYue57VMK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pneumonia-detection-fine-tuning-and-cam (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
